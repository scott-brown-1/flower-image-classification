{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-07 20:59:31.537306: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-07 20:59:31.565347: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-03-07 20:59:31.565378: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-03-07 20:59:31.566185: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-03-07 20:59:31.571710: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-07 20:59:32.085004: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Flatten,Dense, InputLayer\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.layers import LeakyReLU, ReLU\n",
    "\n",
    "from keras.applications import EfficientNetB5\n",
    "\n",
    "USE_GPU = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device mapping:\n",
      "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: NVIDIA GeForce RTX 3050 Ti Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-07 20:59:32.778744: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-07 20:59:32.800152: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-07 20:59:32.800233: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-07 20:59:32.963705: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-07 20:59:32.963780: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-07 20:59:32.963787: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2022] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2024-03-07 20:59:32.963809: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-07 20:59:32.963823: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 1766 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3050 Ti Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "if USE_GPU:\n",
    "    #tf.debugging.set_log_device_placement(True)\n",
    "    sess = tf.compat.v1.Session(config=tf.compat.v1.ConfigProto(log_device_placement=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define path to data and parameters for loader\n",
    "TRAIN_PATH = './data/training/'\n",
    "TEST_PATH = './data/testing/'\n",
    "LABELS_PATH = './data/training_labels.csv'\n",
    "\n",
    "TEST_SIZE = 0.1\n",
    "BATCH_SIZE = 16\n",
    "TARGET_SIZE = (256, 256)\n",
    "\n",
    "N_CLASSES = 5\n",
    "\n",
    "## Encoding labels\n",
    "LABEL_ENCODING = {\n",
    "    'daisy': 0,\n",
    "    'dandelion': 1,\n",
    "    'rose': 2,\n",
    "    'sunflower': 3,\n",
    "    'tulip': 4\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in data and assign labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get labels for train and test data\n",
    "labels_df = pd.read_csv(LABELS_PATH)\n",
    "labels_df['full_id'] = [os.path.join('/home/scottbrown/byu/stat486/projects/flower-image-classification/data/training/training', l) for l in labels_df.ID]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3109 validated image filenames belonging to 5 classes.\n",
      "Found 345 validated image filenames belonging to 5 classes.\n",
      "Found 863 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "## NOTE: `flow_from_dataframe` via ImageDataGenerator is deprecated\n",
    "# In the future, organize directory structure for `flow_from_directory`\n",
    "datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255, validation_split=TEST_SIZE)\n",
    "train_gen = datagen.flow_from_dataframe(\n",
    "    labels_df, \n",
    "    directory=TRAIN_PATH, \n",
    "    target_size=TARGET_SIZE,\n",
    "    subset='training',\n",
    "    x_col='full_id', \n",
    "    y_col='target', \n",
    "    class_mode='categorical', \n",
    "    batch_size=BATCH_SIZE)\n",
    "\n",
    "test_gen = datagen.flow_from_dataframe(\n",
    "    labels_df, \n",
    "    directory=TRAIN_PATH, \n",
    "    target_size=TARGET_SIZE,\n",
    "    subset='validation',\n",
    "    x_col='full_id', \n",
    "    y_col='target', \n",
    "    class_mode='categorical', \n",
    "    batch_size=BATCH_SIZE)\n",
    "\n",
    "## Read in test data to predict on\n",
    "new_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
    "new_gen = new_datagen.flow_from_directory(\n",
    "    TEST_PATH, \n",
    "    target_size=TARGET_SIZE, \n",
    "    class_mode='categorical', \n",
    "    shuffle=False, \n",
    "    batch_size=1)\n",
    "\n",
    "class_names = list(train_gen.class_indices.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preview images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Recreate the above code for train_gen generator object\n",
    "# class_names = list(train_gen.class_indices.keys())\n",
    "# for images, labels in train_gen:\n",
    "#   plt.figure(figsize=(10, 10))\n",
    "#   for i in range(9):\n",
    "#     ax = plt.subplot(3, 3, i + 1)\n",
    "#     lab = class_names[labels[i].argmax()]\n",
    "#     plt.imshow(images[i])\n",
    "#     plt.title(lab)\n",
    "#     plt.axis(\"off\")\n",
    "#   break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base_model = EfficientNetB5(weights='imagenet', include_top=False, drop_connect_rate=0.4, input_shape=(TARGET_SIZE[0], TARGET_SIZE[1], 3))\n",
    "# UNFREEZE_N = 2\n",
    "\n",
    "# # Freeze all but N layers in the base model\n",
    "# for layer in base_model.layers:\n",
    "#     layer.trainable = False\n",
    "\n",
    "# # Optionally, unfreeze the top N layers\n",
    "# for layer in base_model.layers[-UNFREEZE_N:]:\n",
    "#     layer.trainable = True\n",
    "\n",
    "# #x = base_model.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = tf.keras.Sequential([\n",
    "    ## Convolutional => MaxPooling layers\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation=None),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.ReLU(),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.Dropout(0.3),\n",
    "\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation=None),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.ReLU(),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.Dropout(0.3),\n",
    "\n",
    "    ## Fully connected layers\n",
    "    tf.keras.layers.Flatten(),\n",
    "\n",
    "    tf.keras.layers.Dense(128, activation=None),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.ReLU(),\n",
    "    tf.keras.layers.Dropout(0.3),\n",
    "\n",
    "    tf.keras.layers.Dense(128, activation=None),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.ReLU(),\n",
    "    \n",
    "    # ## Output layer\n",
    "    tf.keras.layers.Dense(N_CLASSES, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-07 20:59:33.087176: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-07 20:59:33.087356: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-07 20:59:33.087401: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-07 20:59:33.087724: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-07 20:59:33.087766: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-07 20:59:33.087779: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-07 20:59:33.088049: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-07 20:59:33.088064: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2022] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2024-03-07 20:59:33.088087: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-07 20:59:33.088106: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 1766 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3050 Ti Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "cnn = tf.keras.Sequential([\n",
    "    ## Use base model for transfer learning\n",
    "    #base_model,\n",
    "\n",
    "    ## 3 Convolutional => MaxPooling layers\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation=None),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.ReLU(),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.Dropout(0.3),\n",
    "\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation=None),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.ReLU(),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.Dropout(0.3),\n",
    "\n",
    "    # tf.keras.layers.Conv2D(32, (2, 2)),\n",
    "    # tf.keras.layers.BatchNormalization(),\n",
    "    # tf.keras.layers.ReLU(),\n",
    "    # #tf.keras.layers.MaxPooling2D(),\n",
    "    # tf.keras.layers.Dropout(0.4),\n",
    "\n",
    "    # ## 1 Fully connected layer\n",
    "    tf.keras.layers.Flatten(),\n",
    "\n",
    "    tf.keras.layers.Dense(128, activation=None),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.ReLU(),\n",
    "    tf.keras.layers.Dropout(0.3),\n",
    "\n",
    "    tf.keras.layers.Dense(128, activation=None),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.ReLU(),\n",
    "    \n",
    "    # ## Output layer\n",
    "    tf.keras.layers.Dense(N_CLASSES, activation='softmax')\n",
    "])\n",
    "\n",
    "# cnn = tf.keras.Sequential([\n",
    "#     ## Use base model for transfer learning\n",
    "#     base_model,\n",
    "\n",
    "#     ## 3 Convolutional => MaxPooling layers\n",
    "#     tf.keras.layers.Conv2D(32, (3, 3), activation='relu'),\n",
    "#     tf.keras.layers.MaxPooling2D(),\n",
    "#     tf.keras.layers.Dropout(0.4),\n",
    "\n",
    "#     tf.keras.layers.Flatten(),\n",
    "#     tf.keras.layers.Dense(32, activation='relu'),\n",
    "    \n",
    "#     tf.keras.layers.Dense(N_CLASSES, activation='softmax')\n",
    "# ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base_model = VGG16(weights='imagenet', include_top=False, input_shape=(150, 150, 3))\n",
    "# for layer in base_model.layers:\n",
    "#     layer.trainable = False\n",
    "\n",
    "# x = base_model.output\n",
    "# x = Flatten()(x)\n",
    "# x = Dense(512, activation='relu')(x)\n",
    "# x = Dense(256, activation='relu')(x)\n",
    "# predictions = Dense(4, activation='softmax')(x)\n",
    "\n",
    "# model_transfer = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# model_transfer.compile(optimizer='adam',\n",
    "#                        loss='categorical_crossentropy',\n",
    "#                        metrics=['accuracy'])\n",
    "\n",
    "# model_transfer.fit(train_generator, validation_data=validation_generator, epochs=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.compile(\n",
    "  optimizer='adam',\n",
    "  loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-07 20:59:33.362735: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8904\n",
      "2024-03-07 20:59:33.440864: I external/local_tsl/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2024-03-07 20:59:34.125492: I external/local_tsl/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-07 20:59:35.296453: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:961] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential/dropout/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n",
      "2024-03-07 20:59:36.030215: I external/local_xla/xla/service/service.cc:168] XLA service 0x7fba793c7ef0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-03-07 20:59:36.030245: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 3050 Ti Laptop GPU, Compute Capability 8.6\n",
      "2024-03-07 20:59:36.033955: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1709870376.098167   25949 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "195/195 [==============================] - 18s 74ms/step - loss: 1.2609 - accuracy: 0.4793 - val_loss: 1.5286 - val_accuracy: 0.3710\n",
      "Epoch 2/50\n",
      "195/195 [==============================] - 13s 64ms/step - loss: 0.9212 - accuracy: 0.6423 - val_loss: 1.1844 - val_accuracy: 0.5246\n",
      "Epoch 3/50\n",
      "195/195 [==============================] - 12s 64ms/step - loss: 0.6718 - accuracy: 0.7581 - val_loss: 1.1105 - val_accuracy: 0.5478\n",
      "Epoch 4/50\n",
      "195/195 [==============================] - 12s 64ms/step - loss: 0.3846 - accuracy: 0.8717 - val_loss: 1.2774 - val_accuracy: 0.5536\n",
      "Epoch 5/50\n",
      "195/195 [==============================] - 12s 64ms/step - loss: 0.2178 - accuracy: 0.9360 - val_loss: 1.2145 - val_accuracy: 0.5681\n",
      "Epoch 6/50\n",
      "195/195 [==============================] - 12s 64ms/step - loss: 0.1323 - accuracy: 0.9653 - val_loss: 1.1598 - val_accuracy: 0.6145\n",
      "Epoch 7/50\n",
      "195/195 [==============================] - 12s 63ms/step - loss: 0.0961 - accuracy: 0.9759 - val_loss: 1.6154 - val_accuracy: 0.5014\n",
      "Epoch 8/50\n",
      "195/195 [==============================] - 12s 63ms/step - loss: 0.0737 - accuracy: 0.9836 - val_loss: 1.2070 - val_accuracy: 0.6029\n",
      "Epoch 9/50\n",
      "195/195 [==============================] - 12s 63ms/step - loss: 0.0661 - accuracy: 0.9842 - val_loss: 1.5797 - val_accuracy: 0.5768\n",
      "Epoch 10/50\n",
      "195/195 [==============================] - 12s 63ms/step - loss: 0.0541 - accuracy: 0.9868 - val_loss: 1.8923 - val_accuracy: 0.4841\n",
      "Epoch 11/50\n",
      "195/195 [==============================] - 12s 63ms/step - loss: 0.0619 - accuracy: 0.9858 - val_loss: 1.5500 - val_accuracy: 0.5739\n",
      "Epoch 12/50\n",
      "195/195 [==============================] - 12s 63ms/step - loss: 0.0827 - accuracy: 0.9717 - val_loss: 1.4682 - val_accuracy: 0.5797\n",
      "Epoch 13/50\n",
      "195/195 [==============================] - 12s 63ms/step - loss: 0.0735 - accuracy: 0.9807 - val_loss: 1.4423 - val_accuracy: 0.5797\n",
      "Epoch 14/50\n",
      "195/195 [==============================] - 12s 63ms/step - loss: 0.0669 - accuracy: 0.9794 - val_loss: 1.5911 - val_accuracy: 0.5304\n",
      "Epoch 15/50\n",
      "195/195 [==============================] - 13s 64ms/step - loss: 0.0513 - accuracy: 0.9871 - val_loss: 1.5323 - val_accuracy: 0.6203\n",
      "Epoch 16/50\n",
      "195/195 [==============================] - 12s 63ms/step - loss: 0.0429 - accuracy: 0.9916 - val_loss: 1.4945 - val_accuracy: 0.5942\n",
      "Epoch 17/50\n",
      "195/195 [==============================] - 12s 63ms/step - loss: 0.0463 - accuracy: 0.9881 - val_loss: 1.5190 - val_accuracy: 0.5710\n",
      "Epoch 18/50\n",
      "195/195 [==============================] - 12s 63ms/step - loss: 0.0402 - accuracy: 0.9900 - val_loss: 2.1407 - val_accuracy: 0.4928\n",
      "Epoch 19/50\n",
      "195/195 [==============================] - 12s 63ms/step - loss: 0.0488 - accuracy: 0.9871 - val_loss: 1.6197 - val_accuracy: 0.5681\n",
      "Epoch 20/50\n",
      "195/195 [==============================] - 12s 63ms/step - loss: 0.0563 - accuracy: 0.9842 - val_loss: 1.5261 - val_accuracy: 0.6000\n",
      "Epoch 21/50\n",
      "195/195 [==============================] - 12s 63ms/step - loss: 0.0289 - accuracy: 0.9936 - val_loss: 1.4674 - val_accuracy: 0.5884\n",
      "Epoch 22/50\n",
      "195/195 [==============================] - 12s 63ms/step - loss: 0.0235 - accuracy: 0.9952 - val_loss: 1.4829 - val_accuracy: 0.6116\n",
      "Epoch 23/50\n",
      "195/195 [==============================] - 12s 63ms/step - loss: 0.0405 - accuracy: 0.9884 - val_loss: 2.3506 - val_accuracy: 0.5101\n",
      "Epoch 24/50\n",
      "195/195 [==============================] - 12s 63ms/step - loss: 0.0529 - accuracy: 0.9830 - val_loss: 1.8902 - val_accuracy: 0.5594\n",
      "Epoch 25/50\n",
      "195/195 [==============================] - 12s 62ms/step - loss: 0.0643 - accuracy: 0.9807 - val_loss: 2.1181 - val_accuracy: 0.5333\n",
      "Epoch 26/50\n",
      "195/195 [==============================] - 12s 63ms/step - loss: 0.0556 - accuracy: 0.9839 - val_loss: 2.0486 - val_accuracy: 0.5565\n",
      "Epoch 27/50\n",
      "195/195 [==============================] - 12s 62ms/step - loss: 0.0283 - accuracy: 0.9936 - val_loss: 1.7944 - val_accuracy: 0.5710\n",
      "Epoch 28/50\n",
      "195/195 [==============================] - 12s 63ms/step - loss: 0.0272 - accuracy: 0.9929 - val_loss: 1.9027 - val_accuracy: 0.5768\n",
      "Epoch 29/50\n",
      "195/195 [==============================] - 12s 63ms/step - loss: 0.0285 - accuracy: 0.9920 - val_loss: 1.7607 - val_accuracy: 0.5942\n",
      "Epoch 30/50\n",
      "195/195 [==============================] - 12s 63ms/step - loss: 0.0349 - accuracy: 0.9884 - val_loss: 2.1431 - val_accuracy: 0.5449\n",
      "Epoch 31/50\n",
      "195/195 [==============================] - 12s 63ms/step - loss: 0.0515 - accuracy: 0.9833 - val_loss: 1.5860 - val_accuracy: 0.5913\n",
      "Epoch 32/50\n",
      "195/195 [==============================] - 12s 63ms/step - loss: 0.0184 - accuracy: 0.9968 - val_loss: 1.5781 - val_accuracy: 0.5971\n",
      "Epoch 33/50\n",
      "195/195 [==============================] - 12s 63ms/step - loss: 0.0167 - accuracy: 0.9961 - val_loss: 1.7689 - val_accuracy: 0.6058\n",
      "Epoch 34/50\n",
      "195/195 [==============================] - 12s 63ms/step - loss: 0.0374 - accuracy: 0.9878 - val_loss: 1.9247 - val_accuracy: 0.5710\n",
      "Epoch 35/50\n",
      "195/195 [==============================] - 12s 63ms/step - loss: 0.0323 - accuracy: 0.9881 - val_loss: 2.0943 - val_accuracy: 0.5449\n",
      "Epoch 36/50\n",
      "195/195 [==============================] - 12s 63ms/step - loss: 0.0393 - accuracy: 0.9868 - val_loss: 2.0371 - val_accuracy: 0.5594\n",
      "Epoch 37/50\n",
      "195/195 [==============================] - 12s 63ms/step - loss: 0.0283 - accuracy: 0.9907 - val_loss: 2.6900 - val_accuracy: 0.5043\n",
      "Epoch 38/50\n",
      "195/195 [==============================] - 12s 63ms/step - loss: 0.0254 - accuracy: 0.9926 - val_loss: 1.8960 - val_accuracy: 0.5768\n",
      "Epoch 39/50\n",
      "195/195 [==============================] - 12s 63ms/step - loss: 0.0206 - accuracy: 0.9945 - val_loss: 2.0959 - val_accuracy: 0.5449\n",
      "Epoch 40/50\n",
      "195/195 [==============================] - 12s 62ms/step - loss: 0.0359 - accuracy: 0.9894 - val_loss: 1.9327 - val_accuracy: 0.5797\n",
      "Epoch 41/50\n",
      "195/195 [==============================] - 12s 63ms/step - loss: 0.0225 - accuracy: 0.9945 - val_loss: 2.0746 - val_accuracy: 0.5681\n",
      "Epoch 42/50\n",
      "195/195 [==============================] - 12s 63ms/step - loss: 0.0280 - accuracy: 0.9907 - val_loss: 2.2249 - val_accuracy: 0.5594\n",
      "Epoch 43/50\n",
      "195/195 [==============================] - 12s 62ms/step - loss: 0.0250 - accuracy: 0.9916 - val_loss: 1.7644 - val_accuracy: 0.6000\n",
      "Epoch 44/50\n",
      "195/195 [==============================] - 12s 62ms/step - loss: 0.0321 - accuracy: 0.9894 - val_loss: 2.4984 - val_accuracy: 0.5101\n",
      "Epoch 45/50\n",
      "195/195 [==============================] - 12s 62ms/step - loss: 0.0231 - accuracy: 0.9932 - val_loss: 1.8866 - val_accuracy: 0.5246\n",
      "Epoch 46/50\n",
      "195/195 [==============================] - 12s 62ms/step - loss: 0.0187 - accuracy: 0.9932 - val_loss: 1.8229 - val_accuracy: 0.5826\n",
      "Epoch 47/50\n",
      "195/195 [==============================] - 12s 63ms/step - loss: 0.0225 - accuracy: 0.9936 - val_loss: 1.6459 - val_accuracy: 0.6203\n",
      "Epoch 48/50\n",
      "195/195 [==============================] - 12s 63ms/step - loss: 0.0168 - accuracy: 0.9952 - val_loss: 2.6750 - val_accuracy: 0.5391\n",
      "Epoch 49/50\n",
      "195/195 [==============================] - 12s 63ms/step - loss: 0.0420 - accuracy: 0.9858 - val_loss: 1.7359 - val_accuracy: 0.5826\n",
      "Epoch 50/50\n",
      "195/195 [==============================] - 12s 63ms/step - loss: 0.0353 - accuracy: 0.9868 - val_loss: 1.6783 - val_accuracy: 0.5855\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7fbb021169b0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint_filepath = '/tmp/ckpt/checkpoint.weights.h5'\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=True,\n",
    "    monitor='val_accuracy',\n",
    "    mode='max',\n",
    "    save_best_only=True)\n",
    "\n",
    "cnn.fit( \n",
    "  train_gen,\n",
    "  validation_data=test_gen,\n",
    "  callbacks=[model_checkpoint_callback],\n",
    "  epochs=50\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 0s 20ms/step - loss: 1.6783 - accuracy: 0.5855\n",
      "Test loss: 1.6783088445663452\n",
      "Test accuracy: 0.5855072736740112\n"
     ]
    }
   ],
   "source": [
    "test_eval = cnn.evaluate(test_gen)#X_test, y_test, verboseq0)\n",
    "\n",
    "print('Test loss:', test_eval[0])\n",
    "print('Test accuracy:', test_eval[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "863/863 [==============================] - 3s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = cnn.predict(new_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_files = [f.split('/')[-1] for f in new_gen.filenames]\n",
    "pred_labels = [class_names[i] for i in y_pred.argmax(axis=1)]\n",
    "submission_df = pd.DataFrame({'ID': pred_files, 'Prediction': pred_labels})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Write to CSV\n",
    "submission_df.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stat486",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
